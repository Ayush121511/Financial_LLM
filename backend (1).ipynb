{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMa4RK3P3cdgFPgJeWO8aR3"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":171447,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":145914,"modelId":168485}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes transformers peft accelerate datasets scipy trl rank_bm25 fuzzywuzzy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVxfVRSpU693","executionInfo":{"status":"ok","timestamp":1731991365260,"user_tz":-330,"elapsed":29260,"user":{"displayName":"Aekansh K","userId":"02591405873885289298"}},"outputId":"7d4a2a39-17a9-4f2c-d362-c9cb19eaf6ff","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:23:17.467362Z","iopub.execute_input":"2024-11-19T07:23:17.467637Z","iopub.status.idle":"2024-11-19T07:23:43.169718Z","shell.execute_reply.started":"2024-11-19T07:23:17.467605Z","shell.execute_reply":"2024-11-19T07:23:43.168608Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"seed=42\n\nfrom transformers import set_seed\n\nset_seed(seed)\n\n\n\n\n\nfrom datasets import load_dataset\n\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\n\nfrom tqdm import tqdm\n\nfrom trl import SFTTrainer\n\nimport torch\n\nimport time\n\nimport pandas as pd\n\nimport numpy as np\n\nfrom huggingface_hub import login\n\n\n\nHUGGING_FACE_TOKEN = \"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\"\n\n\n\n# Login programmatically\n\nlogin(HUGGING_FACE_TOKEN)\n\n\n\n\n\n\n\ncompute_dtype = getattr(torch, \"float16\")\n\nbnb_config = BitsAndBytesConfig(\n\n        load_in_4bit=True,\n\n        bnb_4bit_quant_type='nf4',\n\n        bnb_4bit_compute_dtype=compute_dtype,\n\n        bnb_4bit_use_double_quant=False,\n\n    )\n\n\n\nbase_model_id = \"microsoft/phi-2\"\n\nbase_model = AutoModelForCausalLM.from_pretrained(base_model_id,\n\n                                                      device_map='auto',\n\n                                                      quantization_config=bnb_config,\n\n                                                      trust_remote_code=True,\n\n                                                      use_auth_token=True)\n\n\n\nmodel_name='microsoft/phi-2'\n\ntokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True,padding_side=\"left\",add_eos_token=True,add_bos_token=True,use_fast=False)\n\ntokenizer.pad_token = tokenizer.eos_token\n\n\n\n\n","metadata":{"id":"XeOefsBhBkU1","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:23:43.171122Z","iopub.execute_input":"2024-11-19T07:23:43.171420Z","iopub.status.idle":"2024-11-19T07:26:22.989987Z","shell.execute_reply.started":"2024-11-19T07:23:43.171393Z","shell.execute_reply":"2024-11-19T07:26:22.989056Z"}},"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f2452ecba644ed589c3d3e81216589f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4207da2fa6294bababe296e5f93be1d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c615e44cffc24408bb7c67ede152c15a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8757cbe4a98d488fa2c996e05d892cea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9316e7baca5a475a871ce455cb827809"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31109c0569c64bedaa1b1ed382cf2f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2929ca1c3324f28b1745b146841350b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"698bfdef5d2d4ce28d6a823415b47834"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1760796e5fde4a4e95142fd5697c0aa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed6a111063a4c20adca19b66b1ed3db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2367e5f90d79464fa68c8c9b2e964822"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31d7750bbb464a928fdb1c9285a4da85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60ccdacae0044d9aa874a57e47c31b2"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from peft import PeftModel\n\ndef process_query(query):\n\n  ft_model = PeftModel.from_pretrained(base_model, \"/kaggle/input/rag_advisor/other/default/1\",torch_dtype=torch.float16,is_trainable=False)\n\n\n  answer = gen(ft_model,formatted_prompting( ft_model, query ),1500,).split(\"[/INST]\")[1].split(\"<</SYS>>\")[0]\n\n  return answer\n\n\n\n\n\ndef gen(model,prompt,max_length):\n\n\n\n  # Tokenize the input\n\n  input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n\n\n\n  # Generate a response\n\n  output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n\n\n\n  # Decode the response\n\n  response = tokenizer.decode(output[0], skip_special_tokens=True)\n\n  return response","metadata":{"id":"k9TkYgHkDFbP","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:26:22.991046Z","iopub.execute_input":"2024-11-19T07:26:22.991306Z","iopub.status.idle":"2024-11-19T07:26:22.998558Z","shell.execute_reply.started":"2024-11-19T07:26:22.991281Z","shell.execute_reply":"2024-11-19T07:26:22.997469Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"companies = {\n\n    \"NVDA\": \"NVIDIA Corporation\",\n\n    \"AAPL\": \"Apple Inc.\",\n\n    \"MSFT\": \"Microsoft Corporation\",\n\n    \"GOOGL\": \"Alphabet Inc.\",\n\n    \"AMZN\": \"Amazon.com, Inc.\",\n\n    \"GOOG\": \"Alphabet Inc.\",\n\n    \"META\": \"Meta Platforms, Inc.\",\n\n    \"TSLA\": \"Tesla, Inc.\",\n\n    \"AVGO\": \"Broadcom Inc.\",\n\n    \"COST\": \"Costco Wholesale Corporation\",\n\n    \"NFLX\": \"Netflix, Inc.\",\n\n    \"TMUS\": \"T-Mobile US, Inc.\",\n\n    \"ASML\": \"ASML Holding N.V.\",\n\n    \"CSCO\": \"Cisco Systems, Inc.\",\n\n    \"AMD\": \"Advanced Micro Devices, Inc.\",\n\n    \"ADBE\": \"Adobe Inc.\",\n\n    \"PEP\": \"PepsiCo, Inc.\",\n\n    \"LIN\": \"Linde plc\",\n\n    \"AZN\": \"AstraZeneca PLC\",\n\n    \"INTU\": \"Intuit Inc.\",\n\n    \"ISRG\": \"Intuitive Surgical, Inc.\",\n\n    \"TXN\": \"Texas Instruments Incorporated\",\n\n    \"QCOM\": \"QUALCOMM Incorporated\",\n\n    \"BKNG\": \"Booking Holdings Inc.\",\n\n    \"CMCSA\": \"Comcast Corporation\",\n\n    \"PDD\": \"PDD Holdings Inc.\",\n\n    \"AMGN\": \"Amgen Inc.\",\n\n    \"HON\": \"Honeywell International Inc.\",\n\n    \"AMAT\": \"Applied Materials, Inc.\",\n\n    \"ARM\": \"Arm Holdings plc\",\n\n    \"PANW\": \"Palo Alto Networks, Inc.\",\n\n    \"ADP\": \"Automatic Data Processing, Inc.\",\n\n    \"VRTX\": \"Vertex Pharmaceuticals Incorporated\",\n\n    \"SBUX\": \"Starbucks Corporation\",\n\n    \"GILD\": \"Gilead Sciences, Inc.\",\n\n    \"MU\": \"Micron Technology, Inc.\",\n\n    \"INTC\": \"Intel Corporation\",\n\n    \"ADI\": \"Analog Devices, Inc.\",\n\n    \"MELI\": \"MercadoLibre, Inc.\",\n\n    \"LRCX\": \"Lam Research Corporation\",\n\n    \"CTAS\": \"Cintas Corporation\",\n\n    \"PYPL\": \"PayPal Holdings, Inc.\",\n\n    \"MDLZ\": \"Mondelez International, Inc.\",\n\n    \"CRWD\": \"CrowdStrike Holdings, Inc.\",\n\n    \"KLAC\": \"KLA Corporation\",\n\n    \"ABNB\": \"Airbnb, Inc.\",\n\n    \"REGN\": \"Regeneron Pharmaceuticals, Inc.\",\n\n    \"CDNS\": \"Cadence Design Systems, Inc.\",\n\n    \"SNPS\": \"Synopsys, Inc.\",\n\n    \"MAR\": \"Marriott International, Inc.\",\n\n    \"MRVL\": \"Marvell Technology, Inc.\",\n\n    \"FTNT\": \"Fortinet, Inc.\",\n\n    \"DASH\": \"DoorDash, Inc.\",\n\n    \"CEG\": \"Constellation Energy Corporation\",\n\n    \"ORLY\": \"O'Reilly Automotive, Inc.\",\n\n    \"WDAY\": \"Workday, Inc.\",\n\n    \"CSX\": \"CSX Corporation\",\n\n    \"ADSK\": \"Autodesk, Inc.\",\n\n    \"TEAM\": \"Atlassian Corporation\",\n\n    \"CHTR\": \"Charter Communications, Inc.\",\n\n    \"PCAR\": \"PACCAR Inc\",\n\n    \"ROP\": \"Roper Technologies, Inc.\",\n\n    \"TTD\": \"The Trade Desk, Inc.\",\n\n    \"NXPI\": \"NXP Semiconductors N.V.\",\n\n    \"CPRT\": \"Copart, Inc.\",\n\n    \"FANG\": \"Diamondback Energy, Inc.\",\n\n    \"MNST\": \"Monster Beverage Corporation\",\n\n    \"AEP\": \"American Electric Power Company, Inc.\",\n\n    \"PAYX\": \"Paychex, Inc.\",\n\n    \"FAST\": \"Fastenal Company\",\n\n    \"ROST\": \"Ross Stores, Inc.\",\n\n    \"ODFL\": \"Old Dominion Freight Line, Inc.\",\n\n    \"BKR\": \"Baker Hughes Company\",\n\n    \"DDOG\": \"Datadog, Inc.\",\n\n    \"EA\": \"Electronic Arts Inc.\",\n\n    \"KDP\": \"Keurig Dr Pepper Inc.\",\n\n    \"XEL\": \"Xcel Energy Inc.\",\n\n    \"VRSK\": \"Verisk Analytics, Inc.\",\n\n    \"EXC\": \"Exelon Corporation\",\n\n    \"LULU\": \"Lululemon Athletica Inc.\",\n\n    \"CTSH\": \"Cognizant Technology Solutions Corporation\",\n\n    \"KHC\": \"The Kraft Heinz Company\",\n\n    \"GEHC\": \"GE HealthCare Technologies Inc.\",\n\n    \"CCEP\": \"Coca-Cola Europacific Partners PLC\",\n\n    \"MCHP\": \"Microchip Technology Incorporated\",\n\n    \"IDXX\": \"IDEXX Laboratories, Inc.\",\n\n    \"TTWO\": \"Take-Two Interactive Software, Inc.\",\n\n    \"ZS\": \"Zscaler, Inc.\",\n\n    \"DXCM\": \"DexCom, Inc.\",\n\n    \"CSGP\": \"CoStar Group, Inc.\",\n\n    \"ANSS\": \"ANSYS, Inc.\",\n\n    \"ON\": \"ON Semiconductor Corporation\",\n\n    \"CDW\": \"CDW Corporation\",\n\n    \"WBD\": \"Warner Bros. Discovery, Inc.\",\n\n    \"GFS\": \"GlobalFoundries Inc.\",\n\n    \"BIIB\": \"Biogen Inc.\",\n\n    \"ILMN\": \"Illumina, Inc.\",\n\n    \"MDB\": \"MongoDB, Inc.\",\n\n    \"MRNA\": \"Moderna, Inc.\",\n\n    \"DLTR\": \"Dollar Tree, Inc.\",\n\n    \"WBA\": \"Walgreens Boots Alliance, Inc.\"\n\n}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xPHyXMkV6P0","executionInfo":{"status":"ok","timestamp":1731968101334,"user_tz":-330,"elapsed":607,"user":{"displayName":"Aekansh K","userId":"02591405873885289298"}},"outputId":"8035e1c2-c4bf-465d-b4eb-a1775b8cca47","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:26:23.000052Z","iopub.execute_input":"2024-11-19T07:26:23.000341Z","iopub.status.idle":"2024-11-19T07:26:23.014255Z","shell.execute_reply.started":"2024-11-19T07:26:23.000308Z","shell.execute_reply":"2024-11-19T07:26:23.013436Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!pip install yfinance","metadata":{"id":"9O8hVY9gCKCE","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:26:23.017667Z","iopub.execute_input":"2024-11-19T07:26:23.017988Z","iopub.status.idle":"2024-11-19T07:26:53.998264Z","shell.execute_reply.started":"2024-11-19T07:26:23.017962Z","shell.execute_reply":"2024-11-19T07:26:53.997370Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting yfinance\n  Downloading yfinance-0.2.49-py2.py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pandas>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.2.2)\nRequirement already satisfied: numpy>=1.16.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.26.4)\nRequirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.32.3)\nCollecting multitasking>=0.0.7 (from yfinance)\n  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: lxml>=4.9.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (5.3.0)\nRequirement already satisfied: platformdirs>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from yfinance) (3.11.0)\nRequirement already satisfied: pytz>=2022.5 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2024.1)\nRequirement already satisfied: frozendict>=2.3.4 in /opt/conda/lib/python3.10/site-packages (from yfinance) (2.4.4)\nCollecting peewee>=3.16.2 (from yfinance)\n  Downloading peewee-3.17.8.tar.gz (948 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.2/948.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: html5lib>=1.1 in /opt/conda/lib/python3.10/site-packages (from yfinance) (1.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.8.30)\nDownloading yfinance-0.2.49-py2.py3-none-any.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.1/101.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\nBuilding wheels for collected packages: peewee\n  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.8-cp310-cp310-linux_x86_64.whl size=300753 sha256=dae04a1d433268fdc19aa6bd426a2dde0516f2029929838f02f7384885a3beb7\n  Stored in directory: /root/.cache/pip/wheels/75/79/e5/8838db0594cc6c587142fd2563356392ade6255c5930411069\nSuccessfully built peewee\nInstalling collected packages: peewee, multitasking, yfinance\nSuccessfully installed multitasking-0.0.11 peewee-3.17.8 yfinance-0.2.49\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n\nfrom rank_bm25 import *\n\nfrom rank_bm25 import BM25Okapi\n\n\n\n\n\nfor ticker_now,company_now in companies.items():\n\n  companies[ticker_now] = \" \".join(company_now.split()[:-1])\n\n\n\nfrom datetime import datetime, timedelta\n\n\n\ncompany_info = {}\n\nimport yfinance as yf\n\n\n\nfor ticker_now in companies.keys():\n\n    print(ticker_now)\n\n    # Fetch data using yfinance\n\n    ticker = yf.Ticker(ticker_now)\n\n    # Company info\n\n    info = ticker.info\n\n    company_name = info['longName']\n\n    # print(info['longName'])\n\n    market_cap = info.get('marketCap')\n\n    shares_outstanding = info.get('sharesOutstanding')\n\n    sector = info.get('sector')\n\n    industry = info.get('industry')\n\n    exchange = info.get('exchange')\n\n\n\n    # Get today's date\n\n    today = datetime.today()\n\n\n\n    # Get the date of the previous week\n\n    last_week_date = today - timedelta(weeks=1)\n\n    last_last_week_date = today - timedelta(weeks=2)\n\n\n\n    # Stock price movement\n\n    history = ticker.history(start=last_week_date, end=today)\n\n    start_price_last_week = history['Close'].iloc[0]\n\n    end_price_last_week = history['Close'].iloc[-1]\n\n\n\n    history = ticker.history(start=last_last_week_date, end=last_week_date)\n\n    start_price_last_last_week = history['Close'].iloc[0]\n\n    end_price_last_last_week = history['Close'].iloc[-1]\n\n\n\n    # Construct the summary\n\n    summary_now = f\"\"\"\n\n    {company_name} is a leading entity in the {sector} sector. Incorporated and publicly traded, the company has established its reputation as one of the key players in the market.\n\n    As of today, {company_name} has a market capitalization of {market_cap / 1e6:.2f} million USD, with {shares_outstanding / 1e6:.2f} million shares outstanding.\n\n\n\n    {company_name} operates primarily in the {info['country']}, trading under the ticker {ticker_now} on the {exchange}. As a dominant force in the {industry} space, the company continues to innovate and drive progress within the industry.\n\n\n\n    \"\"\"\n\n    print(summary_now)\n\n\n\n    info[\"summary\"] = summary_now\n\n    info[\"start_price_last_week\"] = start_price_last_week\n\n    info[\"end_price_last_week\"] = end_price_last_week\n\n    info[\"start_price_last_last_week\"] = start_price_last_last_week\n\n    info[\"end_price_last_last_week\"] = end_price_last_last_week\n\n    company_info[ticker_now] = info\n\n\n\n\n\ndef get_k_results(query, news_data, k = 5):\n\n    # Preprocess Query Text\n\n    # query = preprocessText(query)\n\n    # print(news_data)\n\n    corpusdata = news_data\n\n    bm25 = BM25Okapi(corpusdata)\n\n    # Get scores\n\n    scores = bm25.get_scores(query)\n\n\n\n    # Entries for specified company name and date\n\n    output = news_data\n\n\n\n    # print(scores)\n\n\n\n    output_index = np.argsort(scores)[-k:][::-1]\n\n\n\n    return [output[i] for i in output_index]\n\n\n\n\n\nfrom fuzzywuzzy import process\n\nimport requests\n\nfrom datetime import datetime, timedelta\n\n\n\ndef last_week_news(ticker_symbol):\n\n\n\n    # Alpha Vantage API Key\n\n    API_KEY = \"A61ML99FXNTBE67B\"\n\n\n\n    # Base URL for Alpha Vantage News API\n\n    BASE_URL = \"https://www.alphavantage.co/query\"\n\n\n\n    # Parameters for the API request\n\n    params = {\n\n        \"function\": \"NEWS_SENTIMENT\",\n\n        \"tickers\": ticker_symbol,  # Replace with desired ticker(s)\n\n        \"apikey\": API_KEY\n\n    }\n\n\n\n    # Making the API request\n\n    response = requests.get(BASE_URL, params=params)\n\n\n\n    results = []\n\n\n\n    # Parsing the response\n\n    if response.status_code == 200:\n\n        data = response.json()\n\n        if \"feed\" in data:\n\n            news_articles = data[\"feed\"]\n\n            last_week = datetime.now() - timedelta(days=7)  # Calculate the date 7 days ago\n\n\n\n            # print(f\"News articles from the last week for {params['tickers']}:\\n\")\n\n            for article in news_articles:\n\n                # Parse the published date using the correct format\n\n                published_date = datetime.strptime(article['time_published'], \"%Y%m%dT%H%M%S\")\n\n\n\n                if published_date >= last_week:\n\n                    # results.append(f\"{article['title']}\")\n\n                    # print(f\"Published Date: {published_date}\")\n\n                    # print(f\"Source: {article['source']}\")\n\n                    results.append(f\"{article['summary']}\")\n\n                    # print(f\"URL: {article['url']}\\n\")\n\n        else:\n\n            print(\"No news articles found.\")\n\n    else:\n\n        print(f\"Error: {response.status_code} - {response.text}\")\n\n\n\n    return results\n\n\n\nimport requests\n\nfrom datetime import datetime, timedelta\n\n\n\ndef last_last_week_news(ticker_symbol):\n\n\n\n    # Alpha Vantage API Key\n\n    API_KEY = \"A61ML99FXNTBE67B\"\n\n\n\n    # Base URL for Alpha Vantage News API\n\n    BASE_URL = \"https://www.alphavantage.co/query\"\n\n\n\n    # Parameters for the API request\n\n    params = {\n\n        \"function\": \"NEWS_SENTIMENT\",\n\n        \"tickers\": ticker_symbol,  # Replace with desired ticker(s)\n\n        \"apikey\": API_KEY\n\n    }\n\n\n\n    # Making the API request\n\n    response = requests.get(BASE_URL, params=params)\n\n\n\n    results = []\n\n\n\n    # Parsing the response\n\n    if response.status_code == 200:\n\n        data = response.json()\n\n        if \"feed\" in data:\n\n            news_articles = data[\"feed\"]\n\n            last_week = datetime.now() - timedelta(days=7)\n\n\n\n            last_last_week = datetime.now() - timedelta(days=14)\n\n\n\n            # print(f\"News articles from the last week for {params['tickers']}:\\n\")\n\n            for article in news_articles:\n\n                # Parse the published date using the correct format\n\n                published_date = datetime.strptime(article['time_published'], \"%Y%m%dT%H%M%S\")\n\n\n\n                if published_date >= last_last_week and published_date <last_week:\n\n                    # results.append(f\"{article['title']}\")\n\n                    # print(f\"Published Date: {published_date}\")\n\n                    # print(f\"Source: {article['source']}\")\n\n                    results.append(f\"{article['summary']}\")\n\n                    # print(f\"URL: {article['url']}\\n\")\n\n        else:\n\n            print(\"No news articles found.\")\n\n    else:\n\n        print(f\"Error: {response.status_code} - {response.text}\")\n\n\n\n    return results\n\n\n\n\n\n\n\ndef get_k_results(query, news_data, k = 5):\n\n    # Preprocess Query Text\n\n    # query = preprocessText(query)\n\n    # print(news_data)\n\n    corpusdata = news_data\n\n    bm25 = BM25Okapi(corpusdata)\n\n    # Get scores\n\n    scores = bm25.get_scores(query)\n\n\n\n    # Entries for specified company name and date\n\n    output = news_data\n\n\n\n    # print(scores)\n\n\n\n    output_index = np.argsort(scores)[-k:][::-1]\n\n\n\n    return [output[i] for i in output_index]\n\n\n\ndef formatted_prompting( model, query):\n\n    company_tickers = list(companies.keys())\n\n    company_tickers.extend(list(companies.values()))\n\n    # print(company_tickers)\n\n    company_now = process.extractOne(query, company_tickers )[0]\n\n    # print(company_now)\n\n    ticker_now = \"\"\n\n    if(company_now in list(companies.keys())):\n\n      ticker_now = company_now\n\n    elif(company_now in list(companies.values())):\n\n      for ticker_name,company_name in companies.items():\n\n        if(company_name==company_now):\n\n          ticker_now = ticker_name\n\n          break\n\n    # ticker = find_key_by_value(companies, company_information[0])\n\n    # print(ticker_now)\n\n\n\n    # Get today's date\n\n    today = datetime.today()\n\n\n\n    # Get the date of the previous week\n\n    last_week_date = today - timedelta(weeks=1)\n\n    last_last_week_date = today - timedelta(weeks=2)\n\n\n\n\n\n    # print(company_information)\n\n    if(last_week_news(ticker_now) != []):\n\n      news_of_last_week = get_k_results(query,last_week_news(ticker_now),5)\n\n    else:\n\n      news_of_last_week = []\n\n    if(last_last_week_news(ticker_now) != []):\n\n      news_of_last_last_week = get_k_results(query,last_last_week_news(ticker_now),5)\n\n    else:\n\n      news_of_last_last_week = []\n\n\n\n    basic_financials = {\n\n        \"bookValue\": company_info[ticker_now][\"bookValue\"],\n\n        \"currentRatio\": company_info[ticker_now][\"currentRatio\"],\n\n        \"operatingCashflow\": company_info[ticker_now][\"operatingCashflow\"],\n\n        \"revenueGrowth\": company_info[ticker_now][\"revenueGrowth\"]\n\n    }\n\n    # print(news_of_last_week)\n\n    # print(news_of_last_last_week)\n\n\n\n    prompt = f\"\"\"[INST]<<SYS>>\n\nYou are a seasoned stock market analyst. Your task is to list the positive developments and potential concerns for companies based on relevant news and basic financials from the past weeks, then provide an analysis and prediction for the companies' stock price movement for the upcoming week. I want to invest my money for 2 years in which company should I invest so as to maximize my profit. Your answer format should be as follows:\n\n\n\n[Positive Developments]:\n\n1. ...\n\n\n\n[Potential Concerns]:\n\n1. ...\n\n\n\n[Prediction & Analysis]\n\nPrediction: ...\n\nAnalysis: ...\n\n\n\n<</SYS>>\n\n\n\n[Company Introduction]: {company_info[ticker_now][\"summary\"]}\n\nFrom {last_last_week_date} to {last_week_date}, {company_info[ticker_now]['longName']}'s stock price changed from {company_info[ticker_now][\"start_price_last_last_week\"]} to {company_info[ticker_now][\"end_price_last_last_week\"]}. News during this period are listed below:\n\n\n\n\"\"\" + \"\\n\".join([f\"[Headline]: {headline}\" for headline in news_of_last_last_week]) + f\"\"\"\n\n\n\nFrom {last_week_date} to {today}, {ticker_now}'s stock price changed from {company_info[ticker_now][\"start_price_last_week\"]} to {company_info[ticker_now][\"end_price_last_week\"]}. News during this period are listed below:\n\n\n\n\"\"\" + \"\\n\".join([f\"[Headline]: {headline}\" for headline in news_of_last_week]) + f\"\"\"\n\n\n\nSome recent basic financials of {ticker_now}, reported at 2024-03-31, are presented below:\n\n\n\n[Basic Financials]:\n\n\n\n\"\"\" + \"\\n\".join([f\"{key}: {value}\" for key, value in basic_financials.items()]) + f\"\"\"\n\n\n\nBased on all the information before {today}, let's first analyze the positive developments and potent ial concerns for {company_info[ticker_now]['longName']}. Come up with 2-4 most important factors respectively and keep them concise. Most factors should be inferred from company related news. Then make your prediction of the {ticker_now} stock price movement for next week. Provide a summary analysis to support your prediction.[/INST]\"\"\"\n\n\n\n\n\n    return prompt\n\n\n\n\n","metadata":{"id":"eZIAbEtvCFUu","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install flask flask-cors pyngrok","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iii-5PTCamYe","executionInfo":{"status":"ok","timestamp":1731991627979,"user_tz":-330,"elapsed":3582,"user":{"displayName":"Aekansh K","userId":"02591405873885289298"}},"outputId":"38fb82d6-21f1-4445-a316-fc2760ffc31e","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:27:14.732883Z","iopub.execute_input":"2024-11-19T07:27:14.733674Z","iopub.status.idle":"2024-11-19T07:27:23.083739Z","shell.execute_reply.started":"2024-11-19T07:27:14.733632Z","shell.execute_reply":"2024-11-19T07:27:23.082562Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: flask in /opt/conda/lib/python3.10/site-packages (3.0.3)\nCollecting flask-cors\n  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\nCollecting pyngrok\n  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from flask) (3.0.4)\nRequirement already satisfied: Jinja2>=3.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.1.2 in /opt/conda/lib/python3.10/site-packages (from flask) (2.2.0)\nRequirement already satisfied: click>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from flask) (8.1.7)\nRequirement already satisfied: blinker>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from flask) (1.8.2)\nRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from pyngrok) (6.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\nDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\nDownloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\nInstalling collected packages: pyngrok, flask-cors\nSuccessfully installed flask-cors-5.0.0 pyngrok-7.2.1\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from flask import Flask, request, jsonify\n\nfrom flask_cors import CORS\n\nfrom pyngrok import ngrok\n\n\n\napp = Flask(__name__)\n\nCORS(app, resources={r\"/chat\": {\"origins\": \"http://localhost:3000\"}})\n\n\n\n@app.route(\"/chat\", methods=[\"POST\"])\n\ndef chat():\n\n    data = request.json\n\n    query = data.get(\"query\", \"\")\n\n\n\n    response = process_query(query)  # Your RAG model\n\n    return jsonify({\"response\": response})\n\n\n\n# # Start the server\n\nngrok.set_auth_token(\"2p3LBRsAGddLLzKD9ytvsCUPaxu_6PxHAmpwDXni9V8faGWvQ\")\n\nngrok_url = ngrok.connect(5000)\n\nprint(f\"Public URL: {ngrok_url}\")\n\napp.run(port=5000)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GakQD5mFaoxJ","executionInfo":{"status":"ok","timestamp":1731992305879,"user_tz":-330,"elapsed":388728,"user":{"displayName":"Aekansh K","userId":"02591405873885289298"}},"outputId":"b23b846b-32ec-4527-d8fa-05c68a70cef5","trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:27:23.085241Z","iopub.execute_input":"2024-11-19T07:27:23.085556Z","iopub.status.idle":"2024-11-19T07:40:15.949962Z","shell.execute_reply.started":"2024-11-19T07:27:23.085520Z","shell.execute_reply":"2024-11-19T07:40:15.948958Z"}},"outputs":[{"name":"stdout","text":"Public URL: NgrokTunnel: \"https://7e4e-34-83-167-138.ngrok-free.app\" -> \"http://localhost:5000\"     \n * Serving Flask app '__main__'\n * Debug mode: off\n","output_type":"stream"},{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2097: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(process_query(\"Should I invest in Amazon stocks\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-19T07:40:15.952302Z","iopub.execute_input":"2024-11-19T07:40:15.952705Z","iopub.status.idle":"2024-11-19T07:40:20.562020Z","shell.execute_reply.started":"2024-11-19T07:40:15.952655Z","shell.execute_reply":"2024-11-19T07:40:20.554631Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprocess_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mShould I invest in Amazon stocks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mprocess_query\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_query\u001b[39m(query):\n\u001b[1;32m      5\u001b[0m   ft_model \u001b[38;5;241m=\u001b[39m PeftModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/rag_advisor/other/default/1\u001b[39m\u001b[38;5;124m\"\u001b[39m,torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,is_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m   answer \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mformatted_prompting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<</SYS>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m answer\n","Cell \u001b[0;32mIn[3], line 28\u001b[0m, in \u001b[0;36mgen\u001b[0;34m(model, prompt, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Generate a response\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Decode the response\u001b[39;00m\n\u001b[1;32m     34\u001b[0m response \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1704\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1703\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1704\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi/modeling_phi.py:1235\u001b[0m, in \u001b[0;36mPhiForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1232\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1235\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1248\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi/modeling_phi.py:980\u001b[0m, in \u001b[0;36mPhiModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    968\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    969\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    970\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m         position_embeddings,\n\u001b[1;32m    978\u001b[0m     )\n\u001b[1;32m    979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 980\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi/modeling_phi.py:708\u001b[0m, in \u001b[0;36mPhiDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, output_attentions, use_cache, past_key_value, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    707\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m attn_outputs, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(attn_outputs)\n\u001b[1;32m    720\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_dropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/phi/modeling_phi.py:645\u001b[0m, in \u001b[0;36mPhiSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings)\u001b[0m\n\u001b[1;32m    642\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    643\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n\u001b[0;32m--> 645\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:500\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_magnitude_vector[active_adapter](\n\u001b[1;32m    493\u001b[0m                 x,\n\u001b[1;32m    494\u001b[0m                 lora_A\u001b[38;5;241m=\u001b[39mlora_A,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m                 base_layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_base_layer(),\n\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m requires_conversion:\n\u001b[0;32m--> 500\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpected_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m         result \u001b[38;5;241m=\u001b[39m result \u001b[38;5;241m+\u001b[39m output\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9}]}